# LLMAgents

[![Awesome](https://camo.githubusercontent.com/64f8905651212a80869afbecbf0a9c52a5d1e70beab750dea40a994fa9a9f3c6/68747470733a2f2f617765736f6d652e72652f62616467652e737667)](https://github.com/zjunlp/LLMAgentPapers) [![License: MIT](https://camo.githubusercontent.com/fd551ba4b042d89480347a0e74e31af63b356b2cac1116c7b80038f41b04a581/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d677265656e2e737667)](https://opensource.org/licenses/MIT) <img src="https://img.shields.io/github/last-commit/tensorflow/tensorflow.svg"/> [![img](https://camo.githubusercontent.com/eafac29b763e18c4d80c680d6a179f348cfa2afbc8d3a45642df19fd580d2404/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d57656c636f6d652d726564)](https://camo.githubusercontent.com/eafac29b763e18c4d80c680d6a179f348cfa2afbc8d3a45642df19fd580d2404/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d57656c636f6d652d726564)
## üìúContent

- [Introduction](#introduction)
- [üåÑ Papers](#papers)
  - [Overview](#overview)
  - [Multiple Agents](#Multiple-Agents)
  - [Agent with the Environment](#Agent-with-the-Environment)

- [üõ†Ô∏è Tools](#tools)
  
## üåÑ Papers

### Overview

1. **Interactive Natural Language Processing**

   Zekun Wang, Ge Zhang, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, Qingqing Zhu, Zhenzhu Yang, Adam Nik, Qi Liu, Chenghua Lin, Shi Wang, Ruibo Liu, Wenhu Chen, Ke Xu, Dayiheng Liu, Yike Guo, Jie Fu. [[abs]](https://arxiv.org/abs/2305.13246), 2023.5

### Multiple Agents

1. **CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society**

   Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani, Dmitrii Khizbullin, Bernard Ghanem. [[abs](https://arxiv.org/abs/2303.17760)], 2023.3

2. **ChatLLM Network: More brains, More intelligence**

   Rui Hao, Linmei Hu, Weijian Qi, Qingliu Wu, Yirui Zhang, Liqiang Nie. [[abs](https://arxiv.org/abs/2304.12998)], 2023.4

3. **Self-collaboration Code Generation via ChatGPT** 

   Yihong Dong, Xue Jiang, Zhi Jin, Ge Li. [[abs](https://arxiv.org/abs/2304.07590)], 2023.4

4. **Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate**

   Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang, Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, Shuming Shi.  [[abs](https://arxiv.org/abs/2305.19118)], 2023.5

5. **Improving Factuality and Reasoning in Language Models through Multiagent Debate**

   Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, Igor Mordatch. [[abs](https://arxiv.org/abs/2305.14325)], 2023.5

6. **Playing repeated games with Large Language Models**

   Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, Eric Schulz. [[abs](https://arxiv.org/abs/2305.16867)], 2023.5
   
7. **ChatGPT/GPT-4 for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities**

   Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang. [[abs](https://arxiv.org/abs/2305.13168)], 2023.5
   
### Agent with the Environment

1. **Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents**

   *Wenlong Huang, Pieter Abbeel, Deepak Pathak, Igor Mordatch*. [[abs](https://arxiv.org/abs/2201.07207)], 2022.1

2. **Inner Monologue: Embodied Reasoning through Planning with Language Models**

   *Wenlong Huang , Fei Xia , Ted Xiao , Harris Chan, Jacky Liang, Pete Florence, Andy Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, Pierre Sermanet, Noah Brown, Tomas Jackson, Linda Luu, Sergey Levine, Karol Hausman, Brian Ichter*. [[abs](https://arxiv.org/abs/2207.05608)], 2022.7

3. **LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models**

   *Chan Hee Song, Jiaman Wu, Clayton Washington, Brian M. Sadler, Wei-Lun Chao, Yu Su*. [[abs](https://arxiv.org/abs/2212.04088)], 2022.12

4. **Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling**

   *Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh Hajishirzi, Sameer Singh, Roy Fox*. [[abs](https://arxiv.org/abs/2301.12050)], 2023.1

5. **Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents**

   *Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, Yitao Liang*. [[abs](https://arxiv.org/abs/2302.01560)], 2023.2

6. **Palm-e: An embodied multimodal language model**

   *Danny Driess, Fei Xia, Mehdi S. M. Sajjadi, Corey Lynch, Aakanksha Chowdhery, Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, Wenlong Huang, Yevgen Chebotar, Pierre Sermanet, Daniel Duckworth, Sergey Levine, Vincent Vanhoucke, Karol Hausman, Marc Toussaint, Klaus Greff, Andy Zeng, Igor Mordatch, Pete Florence.* [[abs](https://arxiv.org/abs/2303.03378)], 2023.3

7. **Chat with the Environment: Interactive Multimodal Perception using Large Language Models**

   *Xufeng Zhao, Mengdi Li, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter*. [[abs](https://arxiv.org/abs/2303.08268)], 2023.3

8. **Generative Agents: Interactive Simulacra of Human Behavior**

   *Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein.* [[abs](https://arxiv.org/abs/2304.03442)], 2023.4

9. **Plan, Eliminate, and Track -- Language Models are Good Teachers for Embodied Agents**

   *Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom Mitchell, Shrimai Prabhumoye*. [[abs](https://arxiv.org/abs/2305.02412)], 2023.5

10. **Voyager: An Open-Ended Embodied Agent with Large Language Models**

    *Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu, Linxi Fan, Anima Anandkumar*. [[abs](https://arxiv.org/abs/2305.16291)], 2023.5

## üõ†Ô∏è Tools

1. **AutoGPT.** 

   Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model.  [[github](https://github.com/Significant-Gravitas/Auto-GPT)] 

2. **CAMEL: Communicative Agents for ‚ÄúMind‚Äù Exploration of Large Scale Language Model Society.** 

   CAMEL is an open-source library designed for the study of autonomous and communicative agents.  [[github](https://github.com/camel-ai/camel)]

3. **GPTeam: Collaborative AI Agents.** 

   GPTeam uses GPT-4 to create multiple agents who collaborate to achieve predefined goals. The main objective of this project is to explore the potential of GPT models in enhancing multi-agent productivity and effective communication. [[github](https://github.com/101dotxyz/GPTeam)]

2. **Transformer Agents.**

   In short, it provides a natural language API on top of transformers: we define a set of curated tools and design an agent to interpret natural language and to use these tools.  [[github](https://huggingface.co/docs/transformers/transformers_agents)]

3. **AgentVerse.** 

   A Framework for Multi-LLM Environment Simulation.  [[github]](https://github.com/OpenBMB/AgentVerse)  

4. **AutoAgents**

   AutoAgents - Complex question answering in LLMs with enhanced reasoning and information-seeking capabilities.  [[github]](https://github.com/AutoLLM/AutoAgents)
